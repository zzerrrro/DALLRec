DALLRec:An effective data augmentation framework with fine-tuning large language model for recommendation

We introduce a novel framework (DALLRec) that enables the efficient  utilizing large language models to alleviate data sparsity issues and enhance recommendation effectiveness

**Main results**

| **data** |          |            |            | **movielens** |            |            |            |            |
| -------- | -------- | ---------- | ---------- | ------------- | ---------- | ---------- | ---------- | ---------- |
| backbone | Variants | R@10       | R@20       | R@50          | N@10       | N@20       | N@50       | P@20       |
| MF-BPR   | Base     | 0.0172     | 0.0304     | 0.0616        | 0.0556     | 0.0800     | 0.1334     | 0.0245     |
|          | DALLRec  | **0.0176** | **0.0320** | **0.0656**    | **0.0576** | **0.0833** | **0.1404** | **0.0264** |
|          | Imporve  | ↑2.33%     | ↑5.26%     | ↑6.49%        | ↑3.59%     | ↑4.13%     | ↑6.17%     | ↑7.76%     |
| NMF      | Base     | 0.0185     | 0.0322     | 0.0670        | 0.0637     | 0.0910     | 0.1523     | 0.0282     |
|          | DALLRec  | **0.0189** | **0.0335** | **0.0716**    | **0.0661** | **0.0954** | **0.1606** | **0.0306** |
|          | Imporve  | ↑2.16%     | ↑4.04%     | ↑2.43%        | ↑3.77%     | ↑4.84%     | ↑5.45%     | ↑8.51%     |
| NGCF     | Base     | 0.0264     | 0.0544     | 0.0908        | 0.0755     | 0.1270     | 0.1906     | 0.0207     |
|          | DALLRec  | **0.0272** | **0.0554** | **0.0943**    | **0.0801** | **0.1315** | **0.1982** | **0.0225** |
|          | Imporve  | ↑3.03%     | ↑1.84%     | ↑3.85%        | ↑6.09%     | ↑3.54%     | ↑3.99%     | ↑8.70%     |
| LightGCN | Base     | 0.0281     | 0.0576     | 0.0950        | 0.0288     | 0.0401     | 0.0544     | 0.0206     |
|          | DALLRec  | **0.0295** | **0.0616** | **0.1007**    | **0.0299** | **0.0425** | **0.0588** | **0.0221** |
|          | Imporve  | ↑4.98%     | ↑6.94%     | ↑6.00%        | ↑3.82%     | ↑3.49%     | ↑8.09%     | ↑7.28%     |
| MMGCN    | Base     | 0.0322     | 0.0647     | 0.1280        | 0.0834     | 0.1304     | 0.1991     | 0.0292     |
|          | DALLRec  | **0.0333** | **0.0675** | **0.1383**    | **0.0857** | **0.1343** | **0.2110** | **0.0311** |
|          | Imporve  | ↑3.41%     | ↑4.33%     | ↑8.05%        | ↑2.75%     | ↑2.99%     | ↑5.98%     | ↑6.51%     |
| GRCN     | Base     | 0.0392     | 0.0711     | 0.1255        | 0.0874     | 0.1346     | 0.2016     | 0.0326     |
|          | DALLRec  | **0.0412** | **0.0734** | **0.1276**    | **0.0895** | **0.1375** | **0.2102** | **0.0351** |
|          | Imporve  | ↑5.10%     | ↑3.23%     | ↑1.67%        | ↑2.40%     | ↑2.15%     | ↑4.26%     | ↑7.67%     |
| MMSSL    | Base     | 0.0469     | 0.0943     | 0.1960        | 0.0888     | 0.1360     | 0.2309     | 0.0356     |
|          | DALLRec  | **0.0502** | **0.1001** | **0.2064**    | **0.0913** | **0.1431** | **0.2436** | **0.0402** |
|          | Imporve  | ↑7.03%     | ↑6.15%     | ↑5.31%        | ↑2.82%     | ↑5.22%     | ↑5.50%     | ↑12.9%     |

We fine-tuning LLM on llama-Factory,Please refer to the specific operation for details:https://github.com/hiyouga/LLaMA-Factory

 We generate enhanced data by running Generate enhanced data.py

```

```